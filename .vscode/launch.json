{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debug: train_CLIP.py",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/LaMed/src/train/train_CLIP.py",
            "args": [
                "--language_model_name_or_path", "./LaMed/pretrained_model/bert_base_uncased",
                "--version", "v0",
                "--local_loss", "False",
                "--gather_loss", "False",
                "--bf16", "True",
                "--output_dir", "./LaMed/output/CLIP-0000",
                "--num_train_epochs", "100",
                "--per_device_train_batch_size", "32",
                "--per_device_eval_batch_size", "4",
                "--gradient_accumulation_steps", "1",
                "--evaluation_strategy", "steps",
                "--eval_accumulation_steps", "1",
                "--eval_steps", "0.04",
                "--save_strategy", "steps",
                "--save_steps", "1000",
                "--save_total_limit", "1",
                "--learning_rate", "1e-4",
                "--weight_decay", "0.1",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "0.001",
                "--gradient_checkpointing", "False",
                "--dataloader_pin_memory", "True",
                "--dataloader_num_workers", "8",
                "--report_to", "tensorboard"
            ],
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${workspaceFolder}"
            },
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Python Debug: pretrain_phi3",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/LaMed/src/train/train.py",
            "args": [
                "--version", "v0",
                "--model_name_or_path", "LaMed/pretrained_model/Phi-3-mini-4k-instruct",
                "--model_type", "lamed_phi3",
                "--vision_tower", "vit3d",
                "--pretrain_vision_model", "./LaMed/pretrained_model/M3D-CLIP/pretrained_ViT.bin",
                "--tune_mm_mlp_adapter", "True",
                "--bf16", "True",
                "--output_dir", "./LaMed/output/LaMed-Phi3-4B-pretrain-0000",
                "--num_train_epochs", "3",
                "--per_device_train_batch_size", "4",
                "--per_device_eval_batch_size", "4",
                "--gradient_accumulation_steps", "1",
                "--evaluation_strategy", "steps",
                "--eval_accumulation_steps", "1",
                "--eval_steps", "0.04",
                "--save_strategy", "steps",
                "--save_steps", "2000",
                "--save_total_limit", "1",
                "--learning_rate", "1e-4",
                "--weight_decay", "0.",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "0.001",
                "--gradient_checkpointing", "False",
                "--dataloader_pin_memory", "True",
                "--dataloader_num_workers", "8",
                "--report_to", "tensorboard"
            ],
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${workspaceFolder}"
            },
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Python Debug: pretrain_llama3",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/LaMed/src/train/train.py",
            "args": [
                "--version", "v0",
                "--model_name_or_path", "./LaMed/pretrained_model/Meta-Llama-3-8B-Instruct/",
                "--model_type", "llama3-8b",
                "--lora_enable", "True",
                "--vision_tower", "vit3d",
                "--pretrain_vision_model", "./LaMed/pretrained_model/M3D-CLIP/pretrained_ViT.bin",
                "--pretrain_mm_mlp_adapter", "./LaMed/output/LaMed-Llama3-8B-pretrain-0000/mm_projector.bin",
                "--segmentation_module", "segvol",
                "--pretrain_seg_module", "./LaMed/pretrained_model/SegVol/pytorch_model.bin",
                "--bf16", "True",
                "--output_dir", "./LaMed/output/LaMed-Llama3-8B-finetune-0000",
                "--num_train_epochs", "3",
                "--per_device_train_batch_size", "8",
                "--per_device_eval_batch_size", "4",
                "--gradient_accumulation_steps", "1",
                "--evaluation_strategy", "steps",
                "--eval_accumulation_steps", "1",
                "--eval_steps", "0.04",
                "--save_strategy", "steps",
                "--save_steps", "1000",
                "--save_total_limit", "1",
                "--learning_rate", "5e-5",
                "--weight_decay", "0.0",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "0.001",
                "--gradient_checkpointing", "False",
                "--dataloader_pin_memory", "True",
                "--dataloader_num_workers", "8",
                "--report_to", "tensorboard"
            ],
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${workspaceFolder}"
            },
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Python Debug: finetune_lora_phi3",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/LaMed/src/train/train.py",
            "args": [
                "--version", "v0",
                "--model_name_or_path", "LaMed/pretrained_model/Phi-3-mini-4k-instruct",
                "--model_type", "phi3",
                "--lora_enable", "True",
                "--vision_tower", "vit3d",
                "--pretrain_vision_model", "./LaMed/pretrained_model/M3D-CLIP/pretrained_ViT.bin",
                "--pretrain_mm_mlp_adapter", "./LaMed/output/LaMed-Phi3-4B-pretrain-0000/mm_projector.bin",
                "--segmentation_module", "segvol",
                "--pretrain_seg_module", "./LaMed/pretrained_model/SegVol/pytorch_model.bin",
                "--bf16", "True",
                "--output_dir", "./LaMed/output/LaMed-Phi3-4B-finetune-0000",
                "--num_train_epochs", "5",
                "--per_device_train_batch_size", "8",
                "--per_device_eval_batch_size", "4",
                "--gradient_accumulation_steps", "1",
                "--evaluation_strategy", "steps",
                "--eval_accumulation_steps", "1",
                "--eval_steps", "0.04",
                "--save_strategy", "steps",
                "--save_steps", "1000",
                "--save_total_limit", "1",
                "--learning_rate", "5e-5",
                "--weight_decay", "0.",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "0.001",
                "--gradient_checkpointing", "False",
                "--dataloader_pin_memory", "True",
                "--dataloader_num_workers", "8",
                "--report_to", "tensorboard"
            ],
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${workspaceFolder}"
            },
            "console": "integratedTerminal",
            "justMyCode": true
        }
    ]
}